{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoReady: On-Demand Spatial Data Prep for Any Canadian Community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import ftplib\n",
    "import geopandas as gpd\n",
    "import ee\n",
    "import geemap\n",
    "import posixpath\n",
    "import fiona\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate and Initialize Google Earth Engine and geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ee.Authenticate()\n",
    "ee.Initialize(project='your-earth-engine-project-id-here')\n",
    "geemap.ee_initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdivision_name = \"Tumbler Ridge\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directory paths\n",
    "base_dir = os.path.dirname(os.getcwd())\n",
    "raw_dir = os.path.join(base_dir, \"data\", \"raw\")\n",
    "proc_dir = os.path.join(base_dir, \"data\", \"processed\")\n",
    "os.makedirs(raw_dir, exist_ok=True)\n",
    "os.makedirs(proc_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRUID-to-Folder Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching the PRUID from Census Subdivions and matching to railway folders by province\n",
    "pruid_to_folder = {\n",
    "    '10': 'nl',   # Newfoundland and Labrador\n",
    "    '11': 'pe',   # PEI (optional)\n",
    "    '12': 'ns',   # Nova Scotia\n",
    "    '13': 'nb',   # New Brunswick\n",
    "    '24': 'qc',   # Quebec\n",
    "    '35': 'on',   # Ontario\n",
    "    '46': 'mb',   # Manitoba\n",
    "    '47': 'sk',   # Saskatchewan\n",
    "    '48': 'ab',   # Alberta\n",
    "    '59': 'bc',   # British Columbia\n",
    "    '60': 'yt',   # Yukon\n",
    "    '61': 'nt',   # NWT\n",
    "    '62': 'nu'    # Nunavut\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Canada Railroad Shapefiles from NRCan via Geo.ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FTP connection details\n",
    "ftp_host = \"ftp.maps.canada.ca\"\n",
    "ftp_base_dir = \"/pub/nrcan_rncan/vector/geobase_nrwn_rfn/\"\n",
    "download_dir = os.path.join(raw_dir, 'railroad_shapefiles')\n",
    "\n",
    "# Ensure the download directory exists\n",
    "os.makedirs(download_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FTP Functions\n",
    "def download_ftp_file(ftp, remote_file, local_file):\n",
    "    with open(local_file, \"wb\") as f:\n",
    "        ftp.retrbinary(f\"RETR {remote_file}\", f.write)\n",
    "\n",
    "\n",
    "def list_ftp_dir(ftp, path):\n",
    "    files = []\n",
    "    ftp.retrlines(f\"NLST {path}\", files.append)\n",
    "    return files\n",
    "\n",
    "\n",
    "# FTP Functions\n",
    "def download_shapefiles_from_ftp(ftp, base_dir, download_dir):\n",
    "    # List the provinces in the base directory (e.g., 'ab', 'bc', etc.)\n",
    "    provinces = list_ftp_dir(ftp, base_dir)\n",
    "\n",
    "    for province in provinces:\n",
    "        # Extract just the province code (e.g., 'yt' for Yukon)\n",
    "        province_code = os.path.basename(province.strip('/'))\n",
    "        province_dir = posixpath.join(base_dir, province_code)\n",
    "\n",
    "        # List the files in the province directory\n",
    "        files = list_ftp_dir(ftp, province_dir)\n",
    "\n",
    "        # If no files are found for the province, skip it\n",
    "        if not files:\n",
    "            print(f\"No files found for province {province_code}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        for file in files:\n",
    "            # Only download English shapefiles (those ending with 'shp_en.zip')\n",
    "            if file.endswith('shp_en.zip'):\n",
    "                remote_file_path = posixpath.join(province_dir, file)\n",
    "\n",
    "                # Correct the local path\n",
    "                province_download_dir = os.path.join(download_dir, province_code)\n",
    "                os.makedirs(province_download_dir, exist_ok=True)\n",
    "\n",
    "                local_file_path = os.path.join(province_download_dir, os.path.basename(file))\n",
    "                print(f\"Downloading {remote_file_path}...\")\n",
    "\n",
    "                try:\n",
    "                    download_ftp_file(ftp, remote_file_path, local_file_path)\n",
    "                    print(f\"Downloaded to {local_file_path}\")\n",
    "\n",
    "                    # Extract the zip file\n",
    "                    with zipfile.ZipFile(local_file_path, 'r') as zip_ref:\n",
    "                        zip_ref.extractall(province_download_dir)\n",
    "                        print(f\"Extracted {local_file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to download or extract {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to FTP\n",
    "ftp = ftplib.FTP(ftp_host)\n",
    "ftp.login()\n",
    "\n",
    "# Download shapefiles\n",
    "download_shapefiles_from_ftp(ftp, ftp_base_dir, download_dir)\n",
    "\n",
    "# Disconnect from FTP\n",
    "ftp.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Industrial Sites from NRCan vie Geo.ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the download directory inside your raw_dir \n",
    "download_dir = os.path.join(raw_dir)\n",
    "os.makedirs(download_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for the 900A dataset\n",
    "url = \"https://ftp.maps.canada.ca/pub/nrcan_rncan/Mining-industry_Industrie-miniere/900A_and_top_100/SHP/900A_74th_2024_shape.zip\"\n",
    "\n",
    "# Path to save the downloaded file\n",
    "zip_path = os.path.join(download_dir, \"900A_74th_shape.zip\")\n",
    "\n",
    "# Download and save the file\n",
    "response = requests.get(url)\n",
    "with open(zip_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Extract the ZIP file directly into the download directory\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    # Extract all files without creating a subdirectory\n",
    "    for file_name in zip_ref.namelist():\n",
    "        zip_ref.extract(file_name, download_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Canada Census Subdivision Boundary zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs for downloading the Census Subdivision boundary zip file\n",
    "csd_zip_url = \"https://www12.statcan.gc.ca/census-recensement/2021/geo/sip-pis/boundary-limites/files-fichiers/lcsd000a21a_e.zip\"\n",
    "csd_zip_path = os.path.join(raw_dir, \"csd_2021_boundaries.zip\")\n",
    "csd_extract_dir = os.path.join(raw_dir, \"csd_2021_boundaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download zip files\n",
    "def download_zip(url, zip_path):\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(f\"Downloading from {url}...\")\n",
    "        response = requests.get(url, verify=False)\n",
    "        if response.status_code == 200:\n",
    "            with open(zip_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Downloaded {zip_path}!\")\n",
    "        else:\n",
    "            raise Exception(f\"Failed to download shapefile from {url}.\")\n",
    "\n",
    "# Download the CSD boundaries zip\n",
    "download_zip(csd_zip_url, csd_zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract CSD Boundary Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the CSD boundary shapefile if not already extracted\n",
    "if not os.path.exists(csd_extract_dir):\n",
    "    with zipfile.ZipFile(csd_zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(csd_extract_dir)\n",
    "        print(f\"Unzipped {csd_zip_path}!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Shapefile & Select AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_file = [f for f in os.listdir(csd_extract_dir) if f.endswith(\".shp\")][0]\n",
    "csd_gdf = gpd.read_file(os.path.join(csd_extract_dir, shp_file))\n",
    "csd_match = csd_gdf[csd_gdf[\"CSDNAME\"].str.lower() == subdivision_name.lower()]\n",
    "\n",
    "if csd_match.empty:\n",
    "    raise ValueError(f\"No subdivision found with name '{subdivision_name}'\")\n",
    "else:\n",
    "    print(f\"Subdivision '{subdivision_name}' found!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproject CSD to WGS 84 for Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject to EPSG:4326 for Earth Engine\n",
    "if csd_match.crs.to_epsg() != 4326:\n",
    "    csd_match = csd_match.to_crs(epsg=4326)\n",
    "    print(\"Reprojected to EPSG:4326 for GEE compatibility.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to ee.Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_json = mapping(csd_match.geometry.values[0])\n",
    "csd_ee_geom = ee.Geometry(geom_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match and Clip Railway Data to AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine PRUID and load matching railway shapefile\n",
    "province_code = str(csd_match[\"PRUID\"].iloc[0])\n",
    "province_folder = pruid_to_folder.get(province_code)\n",
    "\n",
    "if not province_folder:\n",
    "    raise ValueError(f\"Could not determine province folder for PRUID {province_code}\")\n",
    "\n",
    "# Build full filename based on province code\n",
    "track_filename = f\"NRWN_{province_folder}_2_0_TRACK.shp\"\n",
    "rail_path = os.path.join(raw_dir, \"railroad_shapefiles\", province_folder, track_filename)\n",
    "\n",
    "if not os.path.exists(rail_path):\n",
    "    raise FileNotFoundError(f\"Railway track file not found at: {rail_path}\")\n",
    "\n",
    "# Load the shapefile\n",
    "rail_gdf = gpd.read_file(rail_path)\n",
    "\n",
    "# Ensure CRS matches\n",
    "if rail_gdf.crs != csd_match.crs:\n",
    "    rail_gdf = rail_gdf.to_crs(csd_match.crs)\n",
    "\n",
    "# Clip railway data to CSD boundary\n",
    "rail_clipped = gpd.clip(rail_gdf, csd_match)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match and Clip Industrial Sites to AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the industrial sites shapefiles and clip them to the AOI\n",
    "industrial_sites = {\n",
    "    \"MetalWorks\": \"900A_74th_2024_MetalWorks.shp\",\n",
    "    \"OilAndGas\": \"900A_74th_2024_OilAndGas.shp\",\n",
    "    \"ProducingMines\": \"900A_74th_2024_ProducingMines.shp\"\n",
    "}\n",
    "\n",
    "# Load the AOI (Census Subdivision geometry)\n",
    "# Iterate through industrial sites and clip them to the AOI\n",
    "clipped_industrial_sites = {}\n",
    "\n",
    "for site_name, site_shapefile in industrial_sites.items():\n",
    "    site_path = os.path.join(download_dir, \"900A_74th_shape\", site_shapefile)\n",
    "    \n",
    "    if os.path.exists(site_path):\n",
    "        # Load the industrial site shapefile\n",
    "        site_gdf = gpd.read_file(site_path)\n",
    "        \n",
    "        # Ensure CRS matches the AOI's CRS\n",
    "        if site_gdf.crs != csd_match.crs:\n",
    "            print(f\"Reprojecting {site_name} from {site_gdf.crs} to {csd_match.crs}\")\n",
    "            site_gdf = site_gdf.to_crs(csd_match.crs)\n",
    "        else:\n",
    "            print(\"No crs match\")\n",
    "        \n",
    "        # Clip the industrial site to the AOI\n",
    "        clipped_site = gpd.clip(site_gdf, csd_match)\n",
    "        \n",
    "        # Store the clipped data in the dictionary\n",
    "        clipped_industrial_sites[site_name] = clipped_site\n",
    "        print(f\"Clipped {site_name} to AOI.\")\n",
    "    else:\n",
    "        print(f\"File for {site_name} not found at {site_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match and Clip Streams Data to AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths, variables  and view metadata\n",
    "hydrology_gpkg_path = os.path.join(raw_dir, \"rhn_nhn_hhyd\", \"rhn_nhn_hhyd.gpkg\")\n",
    "\n",
    "available_layers = fiona.listlayers(hydrology_gpkg_path)\n",
    "print(\"Available Hydrology Layers:\", available_layers)\n",
    "\n",
    "stream_layer = \"nhn_hhyd_S_L_Watercourse_1\"\n",
    "\n",
    "with fiona.open(hydrology_gpkg_path, layer=stream_layer) as src:\n",
    "    print(\"\\nStream Layer Info:\")\n",
    "    print(f\" - CRS: {src.crs}\")\n",
    "    print(f\" - Geometry Type: {src.schema['geometry']}\")\n",
    "    print(f\" - Properties: {list(src.schema['properties'].keys())}\")\n",
    "    print(f\" - Number of features: {len(src)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and CSD boundary\n",
    "clipped_stream_path = os.path.join(proc_dir, \"clipped_streams.shp\")\n",
    "csd_geom = csd_match.union_all()\n",
    "\n",
    "# Get bounding box of your AOI\n",
    "bbox = csd_geom.bounds  # (minx, miny, maxx, maxy)\n",
    "print(f\"Bounding box of AOI: (minx: {bbox[0]:.2f}, miny: {bbox[1]:.2f}, maxx: {bbox[2]:.2f}, maxy: {bbox[3]:.2f})\")\n",
    "\n",
    "\n",
    "# Load stream layer using bounding box filter\n",
    "print(\"Loading stream layer with bounding box filter...\")\n",
    "streams_gdf = gpd.read_file(\n",
    "    hydrology_gpkg_path,\n",
    "    layer=stream_layer,\n",
    "    bbox=bbox  # Uses Fiona's internal filtering\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(streams_gdf)} features within bounding box\")\n",
    "\n",
    "# Initialize progress bar for filtering by geometry intersection\n",
    "print(\"Filtering features that intersect the CSD geometry...\")\n",
    "intersecting_streams = []\n",
    "\n",
    "for _, row in tqdm(streams_gdf.iterrows(), total=len(streams_gdf), desc=\"Filtering\", unit=\"feat\", dynamic_ncols=True):\n",
    "    if row.geometry.intersects(csd_geom):\n",
    "        intersecting_streams.append(row)\n",
    "\n",
    "# Create new GeoDataFrame from intersecting features\n",
    "intersecting_streams_gdf = gpd.GeoDataFrame(intersecting_streams, crs=streams_gdf.crs)\n",
    "\n",
    "# Save the result to a shapefile\n",
    "intersecting_streams_gdf.to_file(clipped_stream_path)\n",
    "\n",
    "# Final output\n",
    "print(f\"\\nDone! {len(intersecting_streams_gdf)} stream segments that intersect the AOI saved to: {clipped_stream_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch & Clip DEM from GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DEM data\n",
    "dem_source = \"USGS/SRTMGL1_003\"\n",
    "dem = ee.Image(dem_source)\n",
    "clipped_dem = dem.clip(csd_ee_geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine UTM Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily reproject to a projected CRS (World Mercator) for accurate centroid calculation\n",
    "projected_csd = csd_match.to_crs(epsg=3395)  # From WGS 84 to World Mercator\n",
    "centroid = projected_csd.geometry.centroid.iloc[0]\n",
    "\n",
    "# Get longitude and latitude from the centroid (in geographic CRS)\n",
    "# Transform the centroid back to lat/lon in WGS 84 for UTM zone calculation\n",
    "centroid_lonlat = gpd.GeoSeries([centroid], crs=3395).to_crs(epsg=4326).geometry.iloc[0]\n",
    "longitude = centroid_lonlat.x\n",
    "latitude = centroid_lonlat.y\n",
    "\n",
    "# Determine UTM zone based on the longitude\n",
    "utm_zone = int((longitude + 180) // 6) + 1\n",
    "hemisphere_code = 326 if latitude >= 0 else 327  # Northern or Southern Hemisphere\n",
    "utm_crs = f\"EPSG:{hemisphere_code}{utm_zone:02d}\"\n",
    "\n",
    "print(f\"Determined UTM CRS: {utm_crs} (Zone {utm_zone}, {'Northern' if hemisphere_code == 326 else 'Southern'} Hemisphere)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproject All Layers to UTM Zone for Local Analysis Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csd_match_utm = csd_match.to_crs(utm_crs)\n",
    "\n",
    "clipped_dem_utm = clipped_dem.reproject(crs=utm_crs, scale=30)\n",
    "\n",
    "# Create a new dictionary for reprojected industrial sites\n",
    "clipped_industrial_sites_utm = {}\n",
    "for site_name, site_gdf in clipped_industrial_sites.items():\n",
    "    site_gdf_reprojected = site_gdf.to_crs(csd_match_utm.crs)\n",
    "    # Update the new dictionary with the reprojected GeoDataFrame\n",
    "    clipped_industrial_sites_utm[site_name] = site_gdf_reprojected\n",
    "    \n",
    "rail_clipped_utm = rail_clipped.to_crs(csd_match_utm.crs)\n",
    "\n",
    "streams_clipped_utm = intersecting_streams_gdf.to_crs(csd_match_utm.crs)\n",
    "\n",
    "\n",
    "print(f\"CSD Boundary CRS: {csd_match_utm.crs}\")\n",
    "print(f\"DEM CRS: {clipped_dem_utm.projection().getInfo()}\")\n",
    "for site_name, gdf in clipped_industrial_sites_utm.items():\n",
    "    print(f\"{site_name} CRS: {gdf.crs}\")\n",
    "print(f\"Railways CRS: {rail_clipped_utm.crs}\")\n",
    "print(f\"Streams CRS: {streams_clipped_utm.crs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Processed Layers for QGIS Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output folder\n",
    "export_dir = os.path.join(\"..\", \"data\", \"utm\")\n",
    "os.makedirs(export_dir, exist_ok=True)  # Make sure it exists\n",
    "\n",
    "# Export CSD Boundary layer\n",
    "csd_match_utm.to_file(os.path.join(export_dir, \"csd_match_utm.shp\"))\n",
    "\n",
    "# Export DEM from ee\n",
    "geemap.ee_export_image(\n",
    "    clipped_dem_utm,\n",
    "    os.path.join(export_dir, \"clipped_dem_utm.tif\"),\n",
    "    scale=30,\n",
    "    region=None, \n",
    "    file_per_band=False,\n",
    "    crs=\"EPSG:32610\"\n",
    ")\n",
    "\n",
    "# Export industrial sites layer\n",
    "for name, gdf in clipped_industrial_sites_utm.items():\n",
    "    out_path = os.path.join(export_dir, f\"{name}_utm.shp\")\n",
    "    gdf.to_file(out_path)\n",
    "\n",
    "# Export rail layer\n",
    "rail_clipped_utm.to_file(os.path.join(export_dir, \"rail_clipped_utm.shp\"))\n",
    "\n",
    "# Export stream layer\n",
    "streams_clipped_utm.to_file(os.path.join(export_dir, \"streams_clipped_utm.shp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Display & Visualization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the map centered on the subdivision geometry\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(csd_ee_geom, zoom=9)\n",
    "\n",
    "# Add CSD Boundary (AOI)\n",
    "Map.addLayer(csd_ee_geom, {}, f\"CSD Boundary\")\n",
    "\n",
    "# ---- DEM Visualization ----\n",
    "# Get dynamic min/max elevation for DEM within the AOI\n",
    "dem_min_utm = clipped_dem_utm.reduceRegion(\n",
    "    reducer=ee.Reducer.min(), geometry=csd_ee_geom, maxPixels=1e8\n",
    ").get(\"elevation\").getInfo()\n",
    "\n",
    "dem_max_utm = clipped_dem_utm.reduceRegion(\n",
    "    reducer=ee.Reducer.max(), geometry=csd_ee_geom, maxPixels=1e8\n",
    ").get(\"elevation\").getInfo()\n",
    "\n",
    "# Round the min/max values to the nearest whole number\n",
    "dem_min_utm = round(dem_min_utm)\n",
    "dem_max_utm = round(dem_max_utm)\n",
    "\n",
    "# Set visualization parameters dynamically based on the min/max elevation\n",
    "dem_vis_params = {\n",
    "    'min': dem_min_utm,\n",
    "    'max': dem_max_utm,\n",
    "    'palette': ['blue', 'green', 'yellow', 'orange', 'red'] \n",
    "}\n",
    "\n",
    "# Add DEM Layer with dynamic parameters\n",
    "Map.addLayer(clipped_dem_utm, dem_vis_params, f\"DEM\")\n",
    "\n",
    "# Vector Layer Styling\n",
    "rail_style = {\n",
    "    'color': 'black',\n",
    "    'weight': 4,    \n",
    "    'opacity': 0.8,  \n",
    "    'dashArray': '10,5'\n",
    "}\n",
    "\n",
    "streams_style = {\n",
    "    'color': '#0066cc',   \n",
    "    'weight': 1,       \n",
    "    'opacity': 0.8,    \n",
    "}\n",
    "\n",
    "industrial_sites_color = \"#808080\"\n",
    "\n",
    "Map.add_gdf(rail_clipped_utm, layer_name=\"Railways\", info_mode=None, style=rail_style, zoom_to_layer=False)\n",
    "Map.add_gdf(streams_clipped_utm, layer_name=\"Streams\", info_mode=None, style=streams_style, zoom_to_layer=False)\n",
    "\n",
    "for site_type, gdf in clipped_industrial_sites_utm.items():\n",
    "    Map.add_gdf(\n",
    "        gdf,\n",
    "        layer_name=f\"Ind. Sites: {site_type}\",\n",
    "        info_mode=None,\n",
    "        style={\"color\": industrial_sites_color, \"fillOpacity\": 0.7, \"weight\": 2},\n",
    "        zoom_to_layer=False  # Set to True if you want the map to zoom to the layer's extent\n",
    "    )\n",
    "\n",
    "\n",
    "# Add Legends\n",
    "elevation_legend_dict = {\n",
    "    f'Low Elevation ({dem_min_utm}m - {dem_min_utm + round((dem_max_utm - dem_min_utm)/5)}m)': '#0000FF',   # Blue\n",
    "    f'Medium Low Elevation ({dem_min_utm + round((dem_max_utm - dem_min_utm)/5)}m - {dem_min_utm + round(2*(dem_max_utm - dem_min_utm)/5)}m)': '#00FF00',  # Green\n",
    "    f'Medium High Elevation ({dem_min_utm + round(2*(dem_max_utm - dem_min_utm)/5)}m - {dem_min_utm + round(3*(dem_max_utm - dem_min_utm)/5)}m)': '#FFFF00',  # Yellow\n",
    "    f'High Elevation ({dem_min_utm + round(3*(dem_max_utm - dem_min_utm)/5)}m - {dem_min_utm + round(4*(dem_max_utm - dem_min_utm)/5)}m)': '#FFA500',  # Orange\n",
    "    f'Very High Elevation ({dem_min_utm + round(4*(dem_max_utm - dem_min_utm)/5)}m - {dem_max_utm}m)': '#FF0000',  # Red\n",
    "}\n",
    "\n",
    "vector_legend_dictionary = {\n",
    "    \"Industrial Sites (Points)\": \"#4A90E2\",\n",
    "    \"Rail Tracks (Dashed Lines)\": \"#000000\", \n",
    "\"Streams (Lines)\": '#0066cc'\n",
    "}\n",
    "\n",
    "Map.add_legend(title=\"Elevation\", legend_dict=elevation_legend_dict)\n",
    "Map.add_legend(title=\"Vector Layers\", legend_dict=vector_legend_dictionary)\n",
    "\n",
    "# Study area title\n",
    "subdivision_name = csd_match[\"CSDNAME\"].iloc[0]\n",
    "Map.add_legend(title=f\"Study Area: {subdivision_name}\", legend_dict={}, position='bottomleft')\n",
    "\n",
    "# Display the map\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hillshade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hillshade = ee.Terrain.hillshade(clipped_dem_utm)\n",
    "\n",
    "Map.addLayer(hillshade, {'min': 0, 'max': 255}, 'Hillshade')\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = ee.Terrain.slope(clipped_dem_utm)\n",
    "\n",
    "slope_stats = slope.reduceRegion(\n",
    "    reducer=ee.Reducer.minMax(),\n",
    "    geometry=csd_ee_geom,  # Correct geometry\n",
    "    scale=30,\n",
    "    bestEffort=True\n",
    ")\n",
    "\n",
    "# Print the output to inspect the dictionary structure\n",
    "print(slope_stats.getInfo())\n",
    "\n",
    "# Access the correct keys ('slope_min' and 'slope_max')\n",
    "slope_min = slope_stats.get('slope_min').getInfo() \n",
    "max_slope = slope_stats.get('slope_max').getInfo()\n",
    "\n",
    "# Define visualization parameters\n",
    "slope_vis = {\n",
    "    'min': slope_min,\n",
    "    'max': max_slope * .9,\n",
    "    'palette': ['white', 'yellow', 'orange', 'red']\n",
    "}\n",
    "\n",
    "slope_legend_dict = {\n",
    "    'Low': '#FFFFFF',\n",
    "    'Moderate': '#FFFF00',\n",
    "    'Steep': '#FFA500',\n",
    "    'Very Steep': '#FF0000'\n",
    "}\n",
    "\n",
    "# Add layers to the map\n",
    "Map.addLayer(slope, slope_vis, 'Slope')\n",
    "Map.add_legend(\n",
    "    title='Slope',\n",
    "    legend_dict=slope_legend_dict,\n",
    "    position='bottomright'\n",
    ")\n",
    "\n",
    "# Display the map\n",
    "Map.centerObject(clipped_dem_utm, 9)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect = ee.Terrain.aspect(clipped_dem_utm)\n",
    "\n",
    "# Define function to reclassify aspect into directions\n",
    "def classify_aspect(aspect_img):\n",
    "    # Each range gets a direction ID (1 = N, 2 = NE, ..., 8 = NW)\n",
    "    return (aspect_img\n",
    "        .expression(\n",
    "            \"\"\"\n",
    "            b('aspect') <= 22.5 || b('aspect') > 337.5 ? 1 :\n",
    "            b('aspect') > 22.5 && b('aspect') <= 67.5 ? 2 :\n",
    "            b('aspect') > 67.5 && b('aspect') <= 112.5 ? 3 :\n",
    "            b('aspect') > 112.5 && b('aspect') <= 157.5 ? 4 :\n",
    "            b('aspect') > 157.5 && b('aspect') <= 202.5 ? 5 :\n",
    "            b('aspect') > 202.5 && b('aspect') <= 247.5 ? 6 :\n",
    "            b('aspect') > 247.5 && b('aspect') <= 292.5 ? 7 :\n",
    "            b('aspect') > 292.5 && b('aspect') <= 337.5 ? 8 : 0\n",
    "            \"\"\")\n",
    "        .rename('aspect_class')\n",
    "    )\n",
    "\n",
    "# Reclassify aspect\n",
    "aspect_classified = classify_aspect(aspect).clip(csd_ee_geom)\n",
    "\n",
    "# Define visualization parameters (custom palette for 8 directions)\n",
    "aspect_palette = [\n",
    "    'red',      # 1 = N\n",
    "    'orange',   # 2 = NE\n",
    "    'yellow',   # 3 = E\n",
    "    'green',    # 4 = SE\n",
    "    'blue',     # 5 = S\n",
    "    'indigo',   # 6 = SW\n",
    "    'violet',   # 7 = W\n",
    "    'pink'      # 8 = NW\n",
    "]\n",
    "\n",
    "aspect_vis = {\n",
    "    'min': 1,\n",
    "    'max': 8,\n",
    "    'palette': aspect_palette\n",
    "}\n",
    "\n",
    "# Define hex color codes for each aspect direction\n",
    "aspect_legend_dict = {\n",
    "    'North': '#FF0000',\n",
    "    'Northeast': '#FFA500',\n",
    "    'East': '#FFFF00',\n",
    "    'Southeast': '#008000', \n",
    "    'South': '#0000FF',\n",
    "    'Southwest': '#4B0082',\n",
    "    'West': '#8A2BE2',   \n",
    "    'Northwest': '#FFC0CB'\n",
    "}\n",
    "\n",
    "# Add to the map\n",
    "Map.addLayer(aspect_classified, aspect_vis, 'Aspect')\n",
    "Map.add_legend(\n",
    "    title='Aspect Directions',\n",
    "    legend_dict=aspect_legend_dict,\n",
    "    position='bottomright'\n",
    ")\n",
    "\n",
    "# Display map\n",
    "Map.centerObject(clipped_dem_utm, 9)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Raster Projection and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hillshade\n",
    "geemap.ee_export_image(\n",
    "    hillshade,\n",
    "    os.path.join(export_dir, \"hillshade.tif\"),\n",
    "    scale=30,\n",
    "    region = clipped_dem_utm.geometry(), \n",
    "    file_per_band=False,\n",
    "    crs=\"EPSG:32610\"\n",
    ")\n",
    "\n",
    "# Slope\n",
    "geemap.ee_export_image(\n",
    "    slope,\n",
    "    os.path.join(export_dir, \"slope.tif\"),\n",
    "    scale=30,\n",
    "    region = clipped_dem_utm.geometry(), \n",
    "    file_per_band=False,\n",
    "    crs=\"EPSG:32610\"\n",
    ")\n",
    "\n",
    "# Aspect\n",
    "geemap.ee_export_image(\n",
    "    aspect,\n",
    "    os.path.join(export_dir, \"aspect.tif\"),\n",
    "    scale=30,\n",
    "    region = clipped_dem_utm.geometry(), \n",
    "    file_per_band=False,\n",
    "    crs=\"EPSG:32610\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoIgnite2025-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
